Using the base case model of our three candidates and LLM labels (has 8b llama 3.1) as ground truth,
we performed a comparison between them:
==========================================================================================
üèÜ GLiNER TRI-MODEL BENCHMARK SUMMARY
==========================================================================================
         Model  F1-Score  Precision  Recall  Hits (TP)  Misses (FN)  False Alarms (FP)
    NuNER-Zero     0.556      0.508   0.614        151           95                146
    NVIDIA-PII     0.401      0.657   0.289         71          175                 37
GLiNER-X-Large     0.240      0.138   0.919        226           20               1410
==========================================================================================

Round 2 trained model (groq labeled train set (has 8b llama 3.1), gemma labeled eval set) vs NuNER-Zero:
=====================================================================================
üèÜ FINAL PERFORMANCE EVALUATION (Threshold: 0.5)
=====================================================================================
                 Category Base F1 Fine-Tuned F1 Recall Œî Precision Œî
    occupation indication   0.046         0.314    +0.19       -0.35
medical condition related   0.353         0.559    +0.21       -0.03
   children/minor related   0.377         0.753    +0.41       +0.12
-------------------------------------------------------------------------------------
OVERALL SYSTEM SCORE: Baseline F1: 0.259 | Fine-Tuned F1: 0.542
TOTAL PERFORMANCE IMPROVEMENT: +109.5%
=====================================================================================
